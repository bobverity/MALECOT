---
title: "Tutorial: bi-allelic data"
author: "Bob Verity"
date: "`r Sys.Date()`"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Tutorial: bi-allelic data}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

This vignette demonstrates the complete MALECOT analysis pipeline for *bi-allelic* data, i.e. data for which there are two alleles at every locus (the classic example being SNP data).

```{r, echo=FALSE}
set.seed(1)
library(MALECOT)
```

### Simulate some data

MALECOT comes with built-in functions for simulating data from different models. The models used in simulation are exactly the same as the models used in the inference step, allowing us to test the power of the program to arrive at the correct answer. We will simulate a data set of 100 samples, each genotyped at 24 loci and originating from 3 distinct subpopulations. We will assume that the mean complexity of infection (COI) in these subpopulation varies from 1.5 to 3:

```{r}
mysim <- sim_data(n = 100, data_format = "biallelic", L = 24, K = 3, COI_mean = c(1.5,2,3))
```

Running `names(mysim)` we can see that the simulated data contains several elements:

```{r}
names(mysim)
```

The actual data that we are interested in is stored in the "data" element, but notice that we also have a record of the allele frequencies ("true_p"), the complexity of infection ("true_m") and the grouping ("true_group") that were used in generating these data. These additional records can be useful in ground-truthing our estimated values later on, but are not actually used by the program - all that is needed for MALECOT analysis is the "data" element.

Running `head(mysim$data)` we can see the general format required by MALECOT:

```{r}
head(mysim$data)
```

Note that this is the required format **for bi-allelic data only** - multi-allelic data is dealt with in [this vignette](https://bobverity.github.io/MALECOT/articles/tutorial-multiallelic.html).

Data must be in the form of a dataframe, with samples in rows and loci in columns. When using real data, functions such as `read.csv()` and `read.table()` can be used to import data in this format. There are several meta-data columns in the example above, including the sample ID and the population of origin. These meta-data columns are optional and can be turned on or off when loading the data into a project.

The actual genetic data must be one of the following values

* 1 = homozygote for the reference (REF) allele
* 0 = homozygote for the alternative (ALT) allele
* 0.5 = heterozygote (both alleles seen)
* -9 = missing data (this value can be specified, -9 is the default)

MALECOT currently does not use within-sample allele frequency data - for example the raw read depth of REF vs. ALT alleles - and hence read depths should be converted to homozygote/heterozygote calls prior to analysis. MALECOT does, however, include error terms that allow for misclassification of homozygotes as heterozygotes and vice versa, which can account for some noise in the data.

### Create a project and read in data

MALCOT works with projects, which are essentially just simple lists containing all the inputs and outputs of a given analysis. We start by creating a project and loading in our data:

```{r}
myproj <- malecot_project()
myproj <- bind_data_biallelic(myproj, mysim$data, ID_col = 1, pop_col = 2)
```

Notice the general format of the `bind_data()` function, which takes the same project as both input and output. This is the format that most MALECOT functions will take, as it allows a function to modify the project before overwriting the original version. In the input arguments we have specified which columns are meta-data, and all other columns are assumed to contain genetic data.

We can view the project to check that the data have been loaded in correctly:

```{r}
myproj
```

If there have been mistakes in reading in the data, for example if meta-data columns have not been specified and so have been interpreted as genetic data (a common mistake) then this should be visible at this stage.

### Define parameters and run basic MCMC

We can define different models by using different parameter sets. Our first parameter set will represent a simple model in which any COI between 1 and `COI_max` is equally likely *a priori*. We also assume zero error in genotype calls:

```{r}
myproj <- new_set(myproj, name = "uniform model", COI_model = "uniform",
                  COI_max = 20, estimate_error = FALSE, e1 = 0, e2 = 0)
```

Viewing the project we can now see additional properties, including the current active set and the parameters of this set.

```{r}
myproj
```

Now we are ready to run a basic MCMC. We will start by exploring values of K from 1 to 5, using 1000 burn-in iterations and 1000 sampling iterations. By default the MCMC has `auto_converge` turned on, meaning it will test for convergence every `convergence_test` iterations and will exit if convergence is reached (`convergence_test = burnin/10` by default). Hence, it is generally a good idea to set `burnin` to be higher than expected, as the MCMC will adjust this number down if needed. The number of sampling iterations can also be tuned. Our aim when choosing the number of sampling iterations should be to obtain enough samples that our posterior estimates are accurate to an acceptable tolerance level, but not so many that we waste time running the MCMC for long periods past this point. We will look into this parameter again once the MCMC has completed. The most unfamiliar parameter for most users will be the number of "rungs". MALECOT runs multiple MCMC chains simultaneously, each at a different rung on a "temperature ladder". The cold chain is our ordinary MCMC chain, and the hot chains serve two purposes: 1) they improve MCMC mixing, 2) they are central to the GTI method of estimating the evidence for different models. Finally, for the sake of this document we will run with `pb_markdown = TRUE` to avoid printing large amounts of output, but you should run without this argument.

```{r}
myproj <- run_mcmc(myproj, K = 1:5, burnin = 1e4, converge_test = 1e2, samples = 1e3,
                   rungs = 10, pb_markdown =  TRUE)
```

If any values of K failed to converge then we can use the same `run_mcmc()` function to re-run the MCMC for just a single value of K and with different parameters (for example a longer burn-in). This will overwrite the existing output for the specified value of K, but will leave all other values untouched:

### Comparing values of K

The GTI method estimates the evidence for a given model by combining information across multiple temperature rungs. These rungs provide a series of point estimates that together make a "path", and the final evidence estimate is computed from the area between this path and the zero-line. We can visualise this path using the `plot_GTI_path()` function:

```{r}
plot_GTI_path(myproj, K = 3)
```

All plots produced by MALECOT are produced using [ggplot](https://ggplot2.tidyverse.org/), meaning they can be stored and modified later on - for example adding titles, legends etc.

In order for our evidence estimate to be unbiased it is important that the GTI path is relatively smooth. We can modify the smoothness of the path in two ways: 1) by increasing the number of `rungs` used in the MCMC, 2) by changing the value of `GTI_pow` which controls the curvature of the path (higher values lead to more steep curvature). Ideally we want a straight path, i.e. we want as little curvature as possible. In the example above we have a good number of rungs and the path is about as straight as we can get it, so there is no need to re-run the MCMC. **This check should be performed on every value of K**.

Once we are happy with our GTI paths we can look at our evidence estimates, first of all in log space:

```{r}
plot_logevidence_K(myproj)
```

We can see a clear signal for K=3 or higher, and the 95% credible intervals are nice and tight. If we needed tighter credible intervals at this stage then we could re-run the MCMC (for the problem values of K only) with a larger number of `samples`.

We can also plot the full posterior distribution of K, which is obtained by transforming these values out of log space and normalising to sum to one:

```{r}
plot_posterior_K(myproj)
```

This second plot is usually more straightforward to interpret, as it is in linear space and so can be understood in terms of ordinary probability. In this example we can see strong evidence for K=3, with a posterior probability of >0.99. Again, if we had seen wide credible intervals at this stage then it would have been worth repeating the MCMC with a larger number of `samples`, but in this case the result is clear and so there is no need.

### Structure and COI plots

The main result of interest from this sort of analysis is usually the posterior allocation or "structure" plot. This plot contains one bar for each sample, with the proportion of each colour giving the posterior probability of belonging to each of the K subpopulations. We can use the `plot_qmatrix()` function to produce posterior allocation plots for different values of K. The `divide_ind_on` argument adds white lines between individuals, and can be turned off if these lines start getting in the way.

```{r, fig.height=5, fig.width=8}
plot_qmatrix(myproj, K = 2:5, divide_ind_on = TRUE)
```


We can see that for K=3 (the most highly supported value of K) there is a clear split into three distinct subpopulations. The advantage of simulated data is that we can verify that this is the correct grouping by looking at `mysim$true_group`, although obviously this is not possible for real data.

When reporting and publishing results it is a good idea to produce posterior allocation and COI plots for a range of values of K so that the reader has the option of visualising structure at multiple levels, and ideally this should also be backed up by a plot of the model evidence to give some idea of the model fit at each level. At this stage it is worth stressing the point made by many previous authors - **the model used by MALECOT and similar programs is just a cartoon of reality, and there is no strict K in the real world**. Instead, each K captures a different level of population structure, and while the evidence can help guide us towards values of K that fit the data well, it is just a guide and should be taken alongside other biological considerations.

Alongside the posterior allocation plot, we can plot the posterior COI of all samples. Below we have also used the `ggplot2` package to add the true (simulated) COIs to the plot in the form of red crosses.

```{r, fig.height=5, fig.width=8}
posterior_m <- plot_m_quantiles(myproj, K = 3)

library(ggplot2)
posterior_m <- posterior_m + geom_point(aes(x = 1:100, y = mysim$true_m), col = "red", shape = 4)
posterior_m
```

Comparing the posterior 95% credible intervals (black) with the true COIs (red), we can see that the model has done well in some cases and poorly in others. COI estimates are most accurate when the COI is very low (1 or 2), but are highly inaccurate when COI is large. The model has also picked up the general trend in the simulated data, with the mean COI decreasing from the first subpopulation to the last, but it has systematically overestimated the COI across the board. This is down to our choice of uniform prior on COI, which allowed for any COI from 1 to 20 with equal probability *a priori*. In fact, the simulated data are drawn from a more realistic Poisson distribution, in which COIs tend to be clustered around the mean, and so this prior gives too much flexibility for high COIs. We can address this issue along with some other weaknesses in another model run.

### More realistic priors

(TODO)
